# CSE598: Introduction to Deep Learning (Fall 2021) 

## Facial Recognition Using Convolutional Neural Network 

This is the readme file for the "Facial Recognition Using Convolutional Neural Network" project and it contains instructions to run training and inference module.


##### Requirements
The model has been implemented using PyTorch and utilizes other libraries such as scikit-learn etc. To install the required libraries and dependencies create a virtual environment and install all the libraries in the  **requirement.txt**  file.

##### Argument.json file

The **argument.json** file is the meta-data file which contains all the required hyperparameters and path names:

    "trainingSamplesFile": "training.csv",      #   Path to .CSV file containing training sample pairs
    "validationSamplesFile" : "validation.csv", #   Path to .CSV file containing validation sample pairs
    "learningRate" : 0.001,                     #   Learning Rate to be used during training
    "batchSize" : 4,                            #   Batch Size during Training
    "num_epochs" : 10,                          #   Number of epochs for which it will be trained
    "outputVector" : 512,                   	#   Embedded Vector Dimension to be generated by the network
    "bestWeights": "bestWeights.pth",           #   Name/Path to  the best weights model
    "dataRootDirectory":"./dataset",            #   Root Directory of the images
    "threshold_step": 0.05,                     #   Step size to be used while calculating the 'similarity threshold(d)'
    "outputFolder" : "./output"             	#   Output folder to generate inference outputs such as TruePositives etc.

##### Downloading the dataset

Download the dataset from the http://vision.ucsd.edu/~leekc/ExtYaleDatabase/download.html and put them in the **./dataset** folder and rename the folder to **/dataset/extendedPNG_original**


##### Preprocessing the Dataset

We need to convert the images to '.PNG' format and reshape them to 256x256 image shape.To do so run:

> $ python utils/pgm2png.py

This is generate the required images in the **/dataset/extendedPNG_resized** folder 


Rename this folder to **ExtendedYaleB** dataset

##### Overview of all the files and folders

- The **dataset** folder contains all the images in the .PNG format of the Yale Extended Database B. These images have already been resized to 256x256 images.
- The **output** folder contains all the results obtained from our run of the inference module. 
- The **utils** folder contains all the secondary codes used for data-preprocessing etc.
- The *train.py* file is the main file to be used for training. It's the main file that calls all the other functions defined in other files.
The *dataloader.py* file contains the dataloader class which is used to initialize the dataloader object to used during training and validation. 
- The *loss.py* file contains the definition of the Contrastive Loss function
- The *initialize.py* file initializes the Resnet-101 modules with pretrained weights.
- The *trainer.py* file contains the function which trains the model over the required number of epochs and evaluates the contrastive loss over the validation set after each epoch.
- The *findingThreshold.py* file contains the main function to find the best  'similarity threshold(d)'
- The *inference.py* file is for running the model during the inference time.
- The *analysis.py* files generates the confusion matrix and the classification report after the inference run-time.
- *training.csv* file contains the 40000 training samples to be used for training.
- *validation.csv* files contains the 20000 validation samples to be used for validation and inferencing




##### Running the Pre-trained model

The code base already contains a pre-trained model of the facial recognition network. To run the inference on the validation set simply run:
>$ python inference.py --d=0.25  --imageOut=True

#####
This run will generate 4 folders and 2 pickle files inside the ./ouput folder:
    -   truePositves (Samples in the validation set predicted by the model as similar and groundtruth being similar)
    -   trueNegatives (Samples in the validation set predicted by the model as dissimilar and groundtruth being dissimilar)
    -   falsePositives (Samples in the validation set predicted by the model as similar but the groundtruth being dissmilar)
    -   falseNegatives (Samples in the validation set predicted by the model as dissimilar but the groundtruth being similar)
    -   predictedLabels.pkl pickle file containing all groundtruth labels
    -   trueLabels.pkl pickle file containing all the predicted labels from the network
    
#### Training From Scratch

To train the model, generate .CSV files similar to *training.csv* and *validation.csv* files and fill the required arguments in *arguments.json* file. Then simply run:

> $ python train.py

#### Finding the The Similarity Threshold (d)
To find the similarity threshold run the following after training the model.
> python findingThreshold.py

Make sure you manually remember the best value of 'd'. The current implementation doesn't save the best value of 'd'.

#### Running the Inference Module
The inference module takes two additional parameters:
-   d (Similarity Threshold. Set to default 0.25)
-   imageOut (Generate Inference Pair Images and their predicted lables. Sorts them in the 4 folders discussed earlier. Default is False)

#### Running the analysis module

Once the inference is complete, make sure the predictedLabels.pkl and trueLabels.pkl are present in the ouput folder path as mentioned in the *arguments.json* file.

To run the analysis module:

> python analysis.py

This will generate the confusion matrix and the classification report.






